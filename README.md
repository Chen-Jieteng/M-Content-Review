# M-Content-Review （Machine Content Review）
## 项目描述
开源机审模型全流程项目，模拟针对通用APP的短视频、图文、广告的机审模型架构的实践及优化，以提供现有模型框架一个新路径及思路。
测试APP为开源项目douyin：本项目对douyin（https://github.com/zyronon/douyin）的页面进行了增删查改，添加了模拟广告运作机制。

## 项目架构
视频/音频/文本输入 --(视频抽帧+音频转写等)--> 三种高维数据的多模态解析层 --(Structured context生成)--> Prompt审核引擎（大模型架构和大模型本身）--(效果分析和可视化)

## 审核平台页面


## 现存机审模型的缺陷（截止2025年8月8日）：
无法精准过滤以下视频、文本、图片、广告等内容：
- 隐性低俗段子或煽动言论
- 模糊化打码视频：虽然内容被打码，但是机审应该注重内容质量、如果内容质量低俗，就算打码模糊化也算违规。
- 危险内容（危险诱导）：包括危险骑行（摩托）、自动驾驶炫耀
- 故意隐瞒事实的广告：未出现疗效敏感词的健康产品介绍、虚假宣传、恶意推广
- 涉嫌摆拍的不实内容（无法通过单视频审核得出结论）：比如之前有一个男博主摆拍假装与自己的男老板发生关系，以博取眼球，实际为摆拍的低质量内容，这种内容需要模型自主深挖博主的历史发表内容来寻找上下文线索，即可做出合理审判。
- 无法通过算法识别的违规或低质量内容：涉X内容、架空世界或历史扭曲内容（因为LLM幻听未能分辨）、隐性擦边内容、隐性未成年涉黄、虚假新闻（LLM幻听无法分辨）、谐音或错别字文本、图片嵌入字模糊内容、AIGC模糊内容、误杀内容
- 无法通过审核员的潜在违规或低质量内容：涉X内容、涉外谣言、XXXX水军言论、其他需长期滞留海外以及了解海外生态的人才能精准识别潜在内容质量风险

可能会误判的情况：
- 原创二次创作（会被误判成重复内容）
- 正常经处理后的恐怖片剧情
- 人体艺术鉴赏
- 性教育科普视频、以及其他对国家性教育有益的视频
- 由LLM幻听引起的事实误判：可通过MAD系统改善

流量池分配机制失效或者匹配误判的场景：
- 本该在低流量池的低质内容，却出现在高流量池的内容
- 本该在高流量池的优质内容，却出现在低流量池的内容

## 缺陷分析的证据来源
收集观察实例，均为APP内真实视频，通过收藏视频在特定观察周期（2025年8月8日10:35 - 8月10日23:59）内观察视频是否下架，再通过对这些不符合审核标准却未被精准下架的视频注入本项目模型测试，研究分析其表现和审核效果。

## 技术选型
模型层：多模态+LLM
- 视频/图像识别：YOLOv10，NudeNet v2，或者OpenAI CLIP/Qwen-VL-Max
- 音频转写：whisper-v3-large或者sensevoice
- 大语言模型：国际版本：GPT系列、claude系列、gemini系列；国产版本：qwen2.5-72B，Yi-Large-Turbo、GLM-4-Long
- 推理框架：vLLM

工程层：prompt管理 + 数据流 
- prompt管理：langchain（智能体用），llamaindex（多模态用）

数据处理
- 视频抽帧：ffmpeg和PyAV
- 数据存储：DuckDB轻量分析 或者 ClikeHouse大规模分析
- 流式处理：Kafka和Flink

部署
- FastAPI，通过REST和WebSocket实现

## 可视化层
- 前端：Streamlist或者Next.js混搭ShadCN UI
- 图表：ECharts或Plotly Dash

## 机审内容范围定义
- 短视频：视频流、图片、文本、语音统一对齐的视频内容实体
- 评论内容：文本、图片、评论树节点上下文（保证只删除违规的上下文，不会误删整个评论）
- 广告内容：视频流、图片、文本、语音统一对齐的广告内容实体 

## Prompt审核分层机制
- Prompt L1：直接审核
- Prompt L2：违规风险分类、输出分数
- Prompt L3：业务规则（法律敏感内容等）

## 数据来源
- NudeNet数据集（主要是图片）
- OpenNSFW2（普通训练集）
- AVA数据集（黄暴内容）
- COCO+任务检测模型（非违规，但是可做正常人像对照集）
- YouTube-8M（擦边视频）

## 过滤标准
- 文本：敏感词、涉政/色情/暴恐、违禁文案
- 图像/视频：低俗画面、暴力、广告、水印、封面与内容不符、格式错误等
- AI生成：未标注AI生成内容、造谣、不实信息、虚拟人未实名注册
- 涉政敏感内容：历史事件/民族冲突/宗教敏感话题等
- 直播内容：性暗示、不健康表达、迷信、审美扭曲、未成年人不适内容

## 可视化机审结果WebUI
WebUI用风险分数输出：输出违规或者不违规，给出风险等级（100满分）

## 文件输出
- 模型对照表：LLM和LMM等、MoE模型对照组；包括Qwen，Open，豆包，DeepSeek等不同版本的对照实验，写出质检和模型表现相关报告
- 使用小规模（500-800条）人工标注评估集，合成数据进行Prompt压力测试，统计指标（准确率、召回率、误杀率、风险评分；注意这些数据要有一致性，不可没有联系或写假数据）

## 隐私保护措施
- 对所有收集的测试样本作者隐私信息（发表者ID等）进行模糊处理
- 项目遵守MIT协议

## 开源参与者
edwin99

## 项目时间表：2025年8月
8月8日 
- [x] 项目预启动：架构选型、技术选型（模型、可视化路径、部署）、项目规划、机审范围定义、CQC质检规范定义等
- [x] 项目准备：模型下载、依赖安装、环境配置

8月9日
- [x] 项目启动前阶段：上传开源文件至github，
- [ ] 项目启动阶段：模型部署、针对开源模型进行PEFT微调（Adapter-FT、LoRA-FT、P-FT、 Prompt-FT、BitFit、指令FT等）

8月10日
- [ ] 项目启动阶段：代码开发（前后端）+测试
- [ ] 项目启动后阶段：模型基准测试、性能压力测试、迭代微调
- [ ] 项目文件撰写：技术报告、模型审核表现报告

8月11日
- [ ] 项目复盘
- [ ] 项目相关解释文件
- [ ] 项目提交
